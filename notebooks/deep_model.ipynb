{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNxOwadLV3TF3nkAOccnErF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssttefann/EmotionClassification/blob/master/notebooks/deep_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0NC2t-gbt_s",
        "colab_type": "text"
      },
      "source": [
        "# **Emotion Classificaton in Text - Deep Learning Approach**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MXEryxobzA8",
        "colab_type": "code",
        "outputId": "f2f9dd5a-7f55-4fe5-ab1b-82a1db08504c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Tensorflow\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  !pip install -q tf-nightly\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "# General\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot') \n",
        "# plt.style.use('dark_background')\n",
        "\n",
        "try:\n",
        "  import pyprind\n",
        "except Exception:\n",
        "  !pip install pyprind\n",
        "  import pyprind\n",
        "\n",
        "# Data preprocessing\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 532.2MB 29kB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 36.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.8MB 56.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 460kB 59.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 778kB 51.8MB/s \n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hCollecting pyprind\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/30/e76fb0c45da8aef49ea8d2a90d4e7a6877b45894c25f12fb961f009a891e/PyPrind-2.11.2-py3-none-any.whl\n",
            "Installing collected packages: pyprind\n",
            "Successfully installed pyprind-2.11.2\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ikaMJvQ1Y9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acd3NDN3cDFi",
        "colab_type": "text"
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ2tWUNzcEDe",
        "colab_type": "code",
        "outputId": "1997ac8f-b877-483d-c892-6804a9c49b50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# set the seed for entire process\n",
        "# so that results can be reproducible\n",
        "np.random.seed(123)\n",
        "\n",
        "dataset = pd.read_csv(\"/content/drive/My Drive/emotion.data\")\n",
        "dataset.drop(dataset.columns[0], axis='columns', inplace=True)    # drop id column since it won't be used \n",
        "dataset = dataset.reindex(np.random.permutation(dataset.index))   # shuffle data \n",
        "dataset.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>emotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>98301</th>\n",
              "      <td>i am feeling melancholy and have finally pinpo...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41147</th>\n",
              "      <td>i miss having someone to talk to who i have th...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151024</th>\n",
              "      <td>i just feel like i get blamed for everything</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202104</th>\n",
              "      <td>i also apologize for mentioning about him in m...</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73602</th>\n",
              "      <td>im finding is the difference in having a life ...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text emotions\n",
              "98301   i am feeling melancholy and have finally pinpo...  sadness\n",
              "41147   i miss having someone to talk to who i have th...      joy\n",
              "151024       i just feel like i get blamed for everything  sadness\n",
              "202104  i also apologize for mentioning about him in m...    anger\n",
              "73602   im finding is the difference in having a life ...      joy"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIT8NFuUcIn_",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQEc-EQecJo_",
        "colab_type": "code",
        "outputId": "a30235c0-9bf2-43a6-e8d4-00a318d91048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "try:\n",
        "  stop = stopwords.words('english')\n",
        "except LookupError:\n",
        "  import nltk\n",
        "  nltk.download('stopwords')\n",
        "  stop = stopwords.words('english')\n",
        "\n",
        "stop.extend(['img', 'src', 'href'])     # some of these appear in given dataset\n",
        "print(stop[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stGdoVPIcNDb",
        "colab_type": "text"
      },
      "source": [
        "### Tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tKeTx9YcN-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def tokenizer(text):\n",
        "    ''' Removes stop words and special characters,\n",
        "        and returns list of all words that are left\n",
        "\n",
        "        Parameters\n",
        "        -----------\n",
        "        text : string \n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        tokenized : list {string}\n",
        "    '''\n",
        "\n",
        "    text = re.sub('http.*', '', text)                               # delete link references\n",
        "    text = re.sub('[\\W]+', ' ', text.lower()).replace('-', '')      # delete non-word characters [^a-zA-Z0-9]\n",
        "    tokenized = [w for w in text.split() if w not in stop]          # delete stop words ( I, me , a, the)\n",
        "    return tokenized\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0O6PryacTLP",
        "colab_type": "text"
      },
      "source": [
        "### Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNl3RKrecUqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "porter = PorterStemmer() \n",
        "def tokenizer_porter(text):\n",
        "  return [porter.stem(word) for word in tokenizer(text)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inDELbsjconI",
        "colab_type": "text"
      },
      "source": [
        "## Creating Train and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvwvSgPIcqTQ",
        "colab_type": "code",
        "outputId": "d864588c-407e-4def-9dac-c50ea99a587e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "label2id = {\"joy\" : 0, \"sadness\" : 1, \"anger\" : 2, \"fear\" : 3, \"love\" : 4, \"surprise\" : 5}\n",
        "id2label = {0 : \"joy\", 1 : \"sadness\", 2 : \"anger\", 3 : \"fear\", 4 : \"love\", 5 : \"surprise\"}\n",
        "\n",
        "label2col = {\"joy\":\"yellow\", \"sadness\":\"blue\", \"anger\":\"red\", \"fear\":\"grey\", \"love\":\"pink\", \"surprise\":\"orange\"}\n",
        "\n",
        "#label2id = { label : idx for idx, label in enumerate(set(dataset['emotions'].values))}\n",
        "#id2label = { id : label for label, id in label2id.items()}\n",
        "\n",
        "print(label2id)\n",
        "print(id2label)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'joy': 0, 'sadness': 1, 'anger': 2, 'fear': 3, 'love': 4, 'surprise': 5}\n",
            "{0: 'joy', 1: 'sadness', 2: 'anger', 3: 'fear', 4: 'love', 5: 'surprise'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRfrqeW6cru1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset['text'].values, \n",
        "                                                    dataset['emotions'].values, \n",
        "                                                    test_size=0.1, \n",
        "                                                    random_state=123)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QElcfdEZ1QK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = [ label2id[val] for val in y_train]\n",
        "y_test =  [ label2id[val] for val in y_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFUsnhYDcvim",
        "colab_type": "text"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dnct11bcw_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 100\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<OOV>\"\n",
        "training_size = 20000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzy03I1u2tgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "training_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "testing_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "testing_padded = pad_sequences(testing_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIf3KvJL-b6G",
        "colab_type": "code",
        "outputId": "1e4579c7-aad0-40bd-9402-efb9b2691779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes=len(label2id), dtype='float32')\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes=len(label2id), dtype='float32')\n",
        "\n",
        "y_test.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41681, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGzhhKxg92Fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim =  16\n",
        "max_words = max_length\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')\n",
        "])\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd197VBii0v4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')\n",
        "  ])\n",
        "  model.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tir9LG9s3HRA",
        "colab_type": "code",
        "outputId": "19d40d0e-4fd1-4424-c585-42d1e2b6f215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 100, 16)           160000    \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 128)               41472     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 6)                 390       \n",
            "=================================================================\n",
            "Total params: 210,118\n",
            "Trainable params: 210,118\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dJCcRa8ijvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "checkpoint_path = \"/content/drive/My Drive/Colab Notebooks/training_1/cp16dim.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IugV_LoN3I9U",
        "colab_type": "code",
        "outputId": "793b4363-ff98-482c-f80c-5dd230908e75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "\n",
        "\n",
        "history = model.fit(training_padded, \n",
        "                    y_train, epochs=10, \n",
        "                    validation_data=(testing_padded, y_test),\n",
        "                    callbacks=[cp_callback])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "11723/11723 [==============================] - ETA: 0s - loss: 0.7634 - accuracy: 0.7064\n",
            "Epoch 00001: saving model to /content/drive/My Drive/Colab Notebooks/training_1/cp16dim.ckpt\n",
            "11723/11723 [==============================] - 975s 83ms/step - loss: 0.7634 - accuracy: 0.7064 - val_loss: 0.3690 - val_accuracy: 0.8751\n",
            "Epoch 2/10\n",
            "11723/11723 [==============================] - ETA: 0s - loss: 0.3166 - accuracy: 0.8872\n",
            "Epoch 00002: saving model to /content/drive/My Drive/Colab Notebooks/training_1/cp16dim.ckpt\n",
            "11723/11723 [==============================] - 977s 83ms/step - loss: 0.3166 - accuracy: 0.8872 - val_loss: 0.2949 - val_accuracy: 0.8888\n",
            "Epoch 3/10\n",
            "11723/11723 [==============================] - ETA: 0s - loss: 0.2628 - accuracy: 0.8982\n",
            "Epoch 00003: saving model to /content/drive/My Drive/Colab Notebooks/training_1/cp16dim.ckpt\n",
            "11723/11723 [==============================] - 978s 83ms/step - loss: 0.2628 - accuracy: 0.8982 - val_loss: 0.2565 - val_accuracy: 0.8968\n",
            "Epoch 4/10\n",
            "11723/11723 [==============================] - ETA: 0s - loss: 0.2132 - accuracy: 0.9102\n",
            "Epoch 00004: saving model to /content/drive/My Drive/Colab Notebooks/training_1/cp16dim.ckpt\n",
            "11723/11723 [==============================] - 970s 83ms/step - loss: 0.2132 - accuracy: 0.9102 - val_loss: 0.2122 - val_accuracy: 0.9081\n",
            "Epoch 5/10\n",
            "11723/11723 [==============================] - ETA: 0s - loss: 0.1760 - accuracy: 0.9197\n",
            "Epoch 00005: saving model to /content/drive/My Drive/Colab Notebooks/training_1/cp16dim.ckpt\n",
            "11723/11723 [==============================] - 972s 83ms/step - loss: 0.1760 - accuracy: 0.9197 - val_loss: 0.1754 - val_accuracy: 0.9150\n",
            "Epoch 6/10\n",
            "11723/11723 [==============================] - ETA: 0s - loss: 0.1509 - accuracy: 0.9262\n",
            "Epoch 00006: saving model to /content/drive/My Drive/Colab Notebooks/training_1/cp16dim.ckpt\n",
            "11723/11723 [==============================] - 974s 83ms/step - loss: 0.1509 - accuracy: 0.9262 - val_loss: 0.1534 - val_accuracy: 0.9204\n",
            "Epoch 7/10\n",
            "11723/11723 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.9303\n",
            "Epoch 00007: saving model to /content/drive/My Drive/Colab Notebooks/training_1/cp16dim.ckpt\n",
            "11723/11723 [==============================] - 981s 84ms/step - loss: 0.1344 - accuracy: 0.9303 - val_loss: 0.1390 - val_accuracy: 0.9226\n",
            "Epoch 8/10\n",
            " 5299/11723 [============>.................] - ETA: 8:38 - loss: 0.1224 - accuracy: 0.9351"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9voPDBxPilUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "07caacb5-265a-4b9d-f1c0-71136d68030a"
      },
      "source": [
        "model = create_model()\n",
        "\n",
        "model.load_weights(checkpoint_path)\n",
        "\n",
        "loss,acc = model.evaluate(testing_padded,  y_test, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1303/1303 - 21s - loss: 0.1211 - accuracy: 0.9260\n",
            "Restored model, accuracy: 92.60%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRI4nFRKjtlM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b62994a4-0407-43d9-c1e0-90c9a404809c"
      },
      "source": [
        "sentence = [\"I am not happy at all\"]\n",
        "sequences = tokenizer.texts_to_sequences(sentence)\n",
        "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "label_id = np.argmax(model.predict(padded))\n",
        "print(id2label[label_id])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "joy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh0LRl6vkoDK",
        "colab_type": "text"
      },
      "source": [
        "## Second model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2R3eHm4kqG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model_2lstm():\n",
        "  model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')\n",
        "  ])\n",
        "  model.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=\"adam\",\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64WNjHS1nG4b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "074ca682-cb59-4653-c4c5-002b25dfdaa0"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 16)           160000    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 100, 128)          41472     \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 64)                41216     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 6)                 390       \n",
            "=================================================================\n",
            "Total params: 247,238\n",
            "Trainable params: 247,238\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7QTop2olBY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = create_model_2lstm()\n",
        "\n",
        "checkpoint_path_2lstm = \"/content/drive/My Drive/Colab Notebooks/training_1/cp16dim2lstm.ckpt\"\n",
        "checkpoint_dir_2lstm = os.path.dirname(checkpoint_path_2lstm)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback_2lstm = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path_2lstm,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYyoMSNFlR8C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f080b0c6-f0a2-4c41-db42-5e0a431fb3f0"
      },
      "source": [
        "history_2lstm = model2.fit(training_padded, \n",
        "                    y_train, epochs=2, \n",
        "                    validation_data=(testing_padded, y_test),\n",
        "                    callbacks=[cp_callback_2lstm])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "11723/11723 [==============================] - ETA: 0s - loss: 0.2828 - accuracy: 0.8851\n",
            "Epoch 00001: saving model to /content/drive/My Drive/Colab Notebooks/training_1/cp16dim2lstm.ckpt\n",
            "11723/11723 [==============================] - 1791s 153ms/step - loss: 0.2828 - accuracy: 0.8851 - val_loss: 0.1044 - val_accuracy: 0.9391\n",
            "Epoch 2/2\n",
            "11723/11723 [==============================] - ETA: 0s - loss: 0.1018 - accuracy: 0.9382\n",
            "Epoch 00002: saving model to /content/drive/My Drive/Colab Notebooks/training_1/cp16dim2lstm.ckpt\n",
            "11723/11723 [==============================] - 1791s 153ms/step - loss: 0.1018 - accuracy: 0.9382 - val_loss: 0.0938 - val_accuracy: 0.9384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj6cf4t21RZY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "beb1dcc4-47d5-46fd-ff94-cd9a18170819"
      },
      "source": [
        "model2 = create_model_2lstm()\n",
        "\n",
        "model2.load_weights(checkpoint_path_2lstm)\n",
        "\n",
        "loss,acc = model2.evaluate(testing_padded,  y_test, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1303/1303 - 44s - loss: 0.0938 - accuracy: 0.9384\n",
            "Restored model, accuracy: 93.84%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXUdehRU1clj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "770f9b0e-99e2-4426-ba70-b6aef5550c7c"
      },
      "source": [
        "sentence = [\"I am not happy at all\"]\n",
        "sequences = tokenizer.texts_to_sequences(sentence)\n",
        "padded = pad_sequences(sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "label_id = np.argmax(model2.predict(padded))\n",
        "print(id2label[label_id])\n",
        "\n",
        "model2.predict(padded)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "joy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.5013151e-01, 8.3982740e-03, 1.0897810e-01, 3.1975593e-02,\n",
              "        4.5883219e-04, 5.7785037e-05]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULXCC7SZ3RLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.plot(history.history['val_'+string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.legend([string, 'val_'+string])\n",
        "  plt.show()\n",
        "  \n",
        "plot_graphs(history_2lstm, \"accuracy\")\n",
        "plot_graphs(history_2lstm, \"loss\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}